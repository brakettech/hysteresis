{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from daq.pico import CSV\n",
    "from scipy.optimize import fmin, minimize, basinhopping, fsolve\n",
    "from easier import ParamState, shade, Item\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, Ridge\n",
    "from harmonic import Harmonic\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%opts Curve [width=400, height=400 show_grid=True tools=['hover']]\n",
    "%opts Scatter (size=5,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name, fundamental_freq = './data_20171220/20171220-0003.csv', 20\n",
    "file_name, fundamental_freq = './data_20171220/20171220-0004.csv', 20\n",
    "# file_name, fundamental_freq = './data_20171220/20171220-0005.csv', 20\n",
    "# file_name, fundamental_freq = './data_20171220/20171220-0001.csv', 20  # air\n",
    "\n",
    "params = ParamState(\n",
    "    alpha=None,\n",
    "    method='lassocv',\n",
    "    num_freqs=3,\n",
    "    simple_freq_fit=True,\n",
    "    periods=2,\n",
    "    max_sample_freq=1e7,\n",
    "    normalize=True\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarmonicAnalyzer:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.df = None\n",
    "        self.df_fit = None\n",
    "        self.file_name = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def normalizer(self, y, scale=None, return_scale=False):\n",
    "        if scale is None:\n",
    "            scale = 1. / (np.sqrt(2) * np.std(y))\n",
    "        if return_scale:\n",
    "            return scale * y, scale\n",
    "        else:\n",
    "            return scale * y\n",
    "\n",
    "    def demeaner(self, df):\n",
    "        for col in df.columns:\n",
    "            if col == 't':\n",
    "                continue\n",
    "            df.loc[:, col] = df.loc[:, col] - df.loc[:, col].mean()\n",
    "        return df\n",
    "    \n",
    "    def fit(self, file_name, fundamental_freq):\n",
    "        self.file_name = file_name\n",
    "        self.df, self.df_fit = self._get_fit_frames(file_name, fundamental_freq)\n",
    "        \n",
    "    def _get_phase_delta(self, h_obj1, h_obj2, t_ref):\n",
    "        zero1 = fsolve(h_obj1.predict, t_ref)\n",
    "        zero2 = fsolve(h_obj2.predict, zero1)\n",
    "        delta = zero2 - zero1\n",
    "        return delta\n",
    "        \n",
    "    def _get_fit_frames(self, file_name, fundamental_freq):\n",
    "        # make a local reference to the params\n",
    "        params = self.params\n",
    "        \n",
    "        # load the file and make sure all data has zero-mean\n",
    "        df = CSV(file_name, a='sig_gen', b='res_volt', c='sec_volt', max_sample_freq=params.max_sample_freq).df\n",
    "        df = self.demeaner(df)  \n",
    "\n",
    "        # refine the guess of the fundamental frequency\n",
    "        h = Harmonic(freq=fundamental_freq, num_freqs=1)\n",
    "        f0 = h.refine_frequency(df.t, df.sig_gen, simple=params.simple_freq_fit).f0\n",
    "        \n",
    "\n",
    "        # initialize harmonic objects for resistor and secondary voltages\n",
    "        h_resistor = Harmonic(freq=f0, num_freqs=params.num_freqs)\n",
    "        h_secondary = Harmonic(freq=f0, num_freqs=params.num_freqs)\n",
    "\n",
    "        # fit the harmonic objects to the data\n",
    "        h_resistor.fit(df.t, df.res_volt, method=params.method, alpha=params.alpha)\n",
    "        h_secondary.fit(df.t, df.sec_volt, method=params.method, alpha=params.alpha)\n",
    "        \n",
    "        # create an harmonic object for the actual/expected secondary\n",
    "        h_expected = -h_resistor.derivative()\n",
    "        h_actual = h_secondary.clone()\n",
    "\n",
    "        \n",
    "        # set a reference time to be near the center of the dataset centered on\n",
    "        # an ascending zero crossing of the expected voltage\n",
    "        t_ref = df.t.iloc[len(df) // 2]\n",
    "        t_ref = fsolve(h_expected.predict, t_ref)[0]\n",
    "        if h_expected.derivative().predict(t_ref) < 0:\n",
    "            t_ref = t_ref + 0.5 * h.period\n",
    "        self.t_ref = t_ref\n",
    "\n",
    "        # take derivatives so that I can set the phases so that actual/expected have peaks at same time\n",
    "        h_actual_deriv = h_actual.derivative()\n",
    "        h_expected_deriv = h_expected.derivative()\n",
    "\n",
    "        \n",
    "        # normalize all signals to have fits of amplitudes of about 1\n",
    "        res_scale = sec_scale = 1\n",
    "        if params.normalize:\n",
    "            # run a fit for the entire input dataframe\n",
    "            res_fit = h_resistor.predict(df.t)\n",
    "            sec_fit = h_secondary.predict(df.t)\n",
    "            \n",
    "            # find the scale parameters from the fits\n",
    "            _, res_scale = self.normalizer(res_fit, return_scale=True)\n",
    "            _, sec_scale = self.normalizer(sec_fit, return_scale=True)\n",
    "            \n",
    "            # normalize the raw data by the fit scales\n",
    "            df.loc[:, 'res_volt'] = res_scale * df.res_volt\n",
    "            df.loc[:, 'sec_volt'] = sec_scale * df.sec_volt\n",
    "            \n",
    "        self.index_mu = (res_scale / sec_scale) / f0\n",
    "\n",
    "\n",
    "        # limit the dataframe to be only the number of periods anchored to t_ref\n",
    "        df = df[(df.t >= t_ref) & (df.t < t_ref + params.periods * h.period)].reset_index(drop=True)\n",
    "        \n",
    "        # compute a delta that will make it so that the peaks of actual and expected signals\n",
    "        # coincide as closely as possible\n",
    "        delta1 = self._get_phase_delta(h_expected_deriv, h_actual_deriv, t_ref + .2 * h.period)\n",
    "        delta2 = self._get_phase_delta(h_expected_deriv, h_actual_deriv, t_ref + .7 * h.period)\n",
    "        self.delta = delta = .5 * (delta1 + delta2)\n",
    "        self.index_rho = h.f0 * self.delta[0]\n",
    "\n",
    "        # make fits for actual signal and phase adjusted expected signal\n",
    "        actual_secondary = h_secondary.predict(df.t)\n",
    "        expected_secondary = h_expected.predict(df.t - delta)\n",
    "        \n",
    "        actual_scale = expected_scale = 1.\n",
    "        # normalize the fits if requested\n",
    "        if params.normalize:\n",
    "            actual_secondary, actual_scale = self.normalizer(actual_secondary, return_scale=True)\n",
    "            expected_secondary, expected_scale = self.normalizer(expected_secondary, return_scale=True)\n",
    "\n",
    "        # create a dataframe of the fits\n",
    "        kwargs = dict(\n",
    "            t=df.t,\n",
    "            actual=actual_secondary,\n",
    "            expected=expected_secondary,\n",
    "        )\n",
    "        df_fit = pd.DataFrame(kwargs, columns=kwargs.keys())\n",
    "        \n",
    "        t0_expected_1 = fsolve(lambda t: h_expected.predict(t - delta), self.t_ref)[0]\n",
    "        t0_expected_2 = fsolve(lambda t: h_expected.predict(t - delta), self.t_ref + 0.5 * h.period)[0]\n",
    "        \n",
    "        y0_actual_1 = h_actual.predict(t0_expected_1)\n",
    "        y0_actual_2 = h_actual.predict(t0_expected_2)\n",
    "        y0_expected_1 = h_expected.predict(t0_expected_1 - delta)\n",
    "        y0_expected_2 = h_expected.predict(t0_expected_2 - delta)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.ref_points = Item(\n",
    "            t0_expected_1 = t0_expected_1,\n",
    "            t0_expected_2 = t0_expected_2,\n",
    "            y0_actual_1 = y0_actual_1 * actual_scale,\n",
    "            y0_actual_2 = y0_actual_2 * actual_scale,\n",
    "            y0_expected_1 = y0_expected_1 * expected_scale,\n",
    "            y0_expected_2 = y0_expected_2 * expected_scale,\n",
    "        )\n",
    "        self.index_hyst = abs(y0_actual_2 * actual_scale) + abs(y0_actual_1 * actual_scale)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # return the frames with raw data and fits\n",
    "        return df, df_fit    \n",
    "\n",
    "    \n",
    "ha = HarmonicAnalyzer(params)\n",
    "ha.fit(file_name, fundamental_freq,)\n",
    "df = ha.df\n",
    "dff = ha.df_fit\n",
    "            \n",
    "            \n",
    "display(df.head())\n",
    "display(dff.head())\n",
    "print(ha.ref_points.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve.data (alpha=.3)\n",
    "df_ref_points = pd.DataFrame(\n",
    "    [\n",
    "        [ha.ref_points.t0_expected_1, ha.ref_points.y0_actual_1, ha.ref_points.y0_expected_1],\n",
    "        [ha.ref_points.t0_expected_2, ha.ref_points.y0_actual_2, ha.ref_points.y0_expected_2],\n",
    "    ],\n",
    "    columns=['time', 'actual', 'expected']\n",
    ")\n",
    "    \n",
    "\n",
    "(\n",
    "    (\n",
    "        hv.Curve((dff.actual, dff.expected), kdims=['expected'], vdims=['actual'])\n",
    "        *hv.Scatter((df_ref_points.expected, df_ref_points.actual))\n",
    "    )\n",
    "    + (\n",
    "        hv.Curve((dff.actual, dff.expected - dff.actual), kdims=['expected'], vdims=['actual - expected'])\n",
    "        *hv.Scatter((df_ref_points.expected, df_ref_points.expected - df_ref_points.actual))\n",
    "        * hv.Curve(([0, 0], [-ha.index_hyst / 2, ha.index_hyst / 2.  ]), kdims=['xxx'], vdims=['yyy'])\n",
    "    )\n",
    "    + (\n",
    "        hv.Curve((df.t, df.sec_volt), label='data', kdims=['time'], vdims=['amplitude'], group='data')\n",
    "        * hv.Curve((dff.t, dff.actual), label='actual')\n",
    "        * hv.Curve((dff.t, dff.expected), label='expected')\n",
    "        * hv.Scatter((df_ref_points.time, df_ref_points.actual), kdims=['time'], vdims=['amplitude'], label='actual_zeros')\n",
    "        * hv.Scatter((df_ref_points.time, df_ref_points.expected), kdims=['time'], vdims=['amplitude'], label='expected_zeros')\n",
    "    )\n",
    "    \n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha.index_hyst, ha.index_rho, ha.index_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha.index_hyst, ha.index_rho, ha.index_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
